{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63145bd4-a4ef-4fd2-842e-7eaf0c14ed07",
   "metadata": {},
   "source": [
    "# Introdução às Redes Neurais em Grafos para Séries Temporais\n",
    "\n",
    "As **Redes Neurais em Grafos** (Graph Networks, ou GCNs) têm se mostrado uma ferramenta poderosa para capturar padrões complexos em dados estruturados em forma de grafos, como redes de transporte, redes sociais e interações moleculares. No entanto, muitos problemas no mundo real também envolvem uma dimensão temporal, onde as relações entre as entidades mudam com o tempo. Isso exige a criação de modelos capazes de capturar **dependências espaciais** e **temporais** simultaneamente.\n",
    "\n",
    "A combinação dessas duas dimensões resulta em uma nova classe de problemas conhecidos como **Redes Neurais Espaciais-Temporais em Grafos** (Spatio-Temporal Graph Neural Networks, ou ST-GNNs). Esses modelos são aplicados em uma variedade de tarefas, como previsão de tráfego, análise de redes de sensores e modelagem de interações dinâmicas em redes sociais.\n",
    "\n",
    "Nesta apresentação, exploraremos como a GCN pode ser expandida para lidar com séries temporais, capturando tanto a estrutura do grafo quanto as mudanças ao longo do tempo. Vamos focar em exemplos práticos, como a **previsão de tráfego**, onde o tráfego entre diferentes segmentos de estrada é modelado como um grafo cujas características variam ao longo do tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4ffddd-07f4-46b7-bd86-7b2f2103b663",
   "metadata": {},
   "source": [
    "## Definição\n",
    "\n",
    "Dado um grafo dinâmico $G(t) = (V, E, X_V(t), X_E(t))$, onde:\n",
    "\n",
    "- $V$ é o conjunto de nós (vértices),\n",
    "- $E$ é o conjunto de arestas (conexões entre os nós),\n",
    "- $X_V(t) \\in \\mathbb{R}^{|V| \\times d_V}$ representa as características dos nós (vértices) no tempo $t$, sendo $d_V$ a dimensionalidade das características dos nós,\n",
    "- $X_E(t) \\in \\mathbb{R}^{|E| \\times d_E}$ representa as características das arestas no tempo $t$, sendo $d_E$ a dimensionalidade das características das arestas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e32e4f5d-ed27-4479-a15a-f564c1057b5d",
   "metadata": {},
   "source": [
    "![example](st_gnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7bd8d1-9395-4c5e-96ae-e8df51d34c00",
   "metadata": {},
   "source": [
    "# Motivação: Previsão de Trânsito (GNN + LSTM)\n",
    "\n",
    "Neste exemplo, mostramos como prever as condições de tráfego utilizando redes neurais baseadas em grafos **(GNNs)** combinadas com **LSTM**. O foco é prever os valores futuros da velocidade do tráfego com base em um histórico de dados de uma coleção de segmentos de estrada.\n",
    "\n",
    "Uma solução tradicional para este tipo de problema é tratar a velocidade de tráfego de cada segmento de estrada como uma série temporal individual, prevendo os valores futuros com base nos dados passados do próprio segmento. Entretanto, essa abordagem não considera as influências que os segmentos vizinhos exercem entre si.\n",
    "\n",
    "Para capturar as interações complexas entre os diferentes segmentos de estrada, podemos modelar a rede de tráfego como um grafo, onde a velocidade do tráfego é representada como um sinal associado a esse grafo. Nesta abordagem, implementamos uma arquitetura de rede neural capaz de processar séries temporais sobre um grafo. Primeiramente, mostramos como preparar os dados e criar um `tf.data.Dataset` para previsão com grafos. Em seguida, desenvolvemos um modelo que combina camadas de convolução em grafos com LSTM para realizar a previsão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06851316-9e1d-4433-9934-ae460a0ccdd6",
   "metadata": {},
   "source": [
    "## Carregando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68942a5-9344-4b22-bee1-17f52146a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import typing\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ffef43-8fc0-47a0-959c-951830752ea5",
   "metadata": {},
   "source": [
    "## Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5d98a5-d41b-4699-a347-2133f8c6e971",
   "metadata": {},
   "source": [
    "Utilizamos um conjunto de dados reais de velocidade de tráfego chamado **PeMSD7**. A versão do dataset está no repositório na pasta `data`.\n",
    "\n",
    "O conjunto de dados **PeMSD7** abrange o **Distrito 7 da Califórnia** e consiste nas velocidades de tráfego registradas por **228 sensores** durante o período de maio a junho de 2012, apenas nos dias úteis, com um intervalo de coleta de **5 minutos**.\n",
    "\n",
    "O conjunto de dados é composto por dois arquivos principais:\n",
    "\n",
    "- **PeMSD7_V_228.csv**: Contém as velocidades de tráfego coletadas nessas estações durante os dias úteis dos meses de maio e junho de 2012, com um intervalo de 5 minutos entre as medições.\n",
    "- **PeMSD7_W_228.csv**: Contém as distâncias entre as 228 estações localizadas no Distrito 7 da Califórnia.\n",
    "\n",
    "\n",
    "Uma descrição completa do conjunto de dados pode ser encontrada no artigo de Yu et al. (2018).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a998183-ebda-4579-bbae-e3192d5a6cab",
   "metadata": {},
   "source": [
    "![](PeMSD7-datasets.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2406111-6729-454b-a1ba-b57355c101d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo os arquivos CSV usando numpy\n",
    "route_distances = np.loadtxt(\"../../data/pemsd7/PeMSD7_W_228.csv\", delimiter=\",\")\n",
    "speeds_array = np.loadtxt(\"../../data/pemsd7/PeMSD7_V_228.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774f77e5-60e5-4495-aa54-f03cdb58ab6a",
   "metadata": {},
   "source": [
    "### Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043a304f-f591-49ac-95e6-0aa050b43a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dadea4-2315-40c6-83b0-877fef46f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f354e-3036-4014-9c0b-bbf0cbe0e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(route_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85e2f6-f927-4284-9337-927a88db3347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para subamostrar as estações\n",
    "def subamostrar_estacoes(route_distances, num_estacoes):\n",
    "    indices = np.random.choice(route_distances.shape[0], num_estacoes, replace=False)\n",
    "    sub_route_distances = route_distances[np.ix_(indices, indices)]\n",
    "    return sub_route_distances, indices\n",
    "\n",
    "num_estacoes = 25  # Altere para o número desejado de estações\n",
    "\n",
    "# Subamostrando as estações\n",
    "sub_route_distances, estacoes_indices = subamostrar_estacoes(route_distances, num_estacoes)\n",
    "\n",
    "# Criando o grafo diretamente da matriz de adjacência (distâncias subamostradas)\n",
    "G = nx.from_numpy_array(sub_route_distances)\n",
    "\n",
    "# Plotando o grafo com as arestas ponderadas pelas distâncias\n",
    "pos = nx.spring_layout(G, seed=42)  # Layout do grafo\n",
    "edges = G.edges(data=True)\n",
    "weights = [10 / (w['weight'] + 1) for _, _, w in edges]  # Pesos das arestas\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "nx.draw(G, pos, node_size=50, edge_color=weights, edge_cmap=plt.cm.Blues)\n",
    "\n",
    "plt.title(f\"Grafo de {num_estacoes} Estações com Pesos Baseados nas Distâncias\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b067d-dc26-42c4-91aa-f27fb9ca5e6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# edges = G.edges(data=True)\n",
    "# Outra forma de exibir a matriz de adjacência\n",
    "\n",
    "list(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235d3c82-9a13-4fa3-8c84-201124f00bfa",
   "metadata": {},
   "source": [
    "### Série Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5146554c-0220-43dc-99b4-4f1e0d410895",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89d4dc3-9dda-44b5-8a49-80cde7fedf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd1818-c1a6-4822-ae3c-a7c1d123cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar algumas estradas para plotar\n",
    "selected_routes = [0, 20, 200]\n",
    "\n",
    "# Criar subplots para as séries temporais das velocidades para as estradas selecionadas\n",
    "fig, axs = plt.subplots(len(selected_routes), 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "# Definir um conjunto de cores e estilos de linha para melhorar a visualização\n",
    "colors = ['b', 'g', 'r']\n",
    "\n",
    "for i, route in enumerate(selected_routes):\n",
    "    axs[i].plot(speeds_array[:, route], color=colors[i], linewidth=2, label=f'Estrada {route}')\n",
    "    axs[i].set_title(f\"Sensor {route}\", fontsize=14)\n",
    "    axs[i].set_ylabel(\"Velocidade (km/h)\", fontsize=12)\n",
    "    axs[i].grid(True, which='both', linewidth=0.5, alpha=0.7)\n",
    "    axs[i].legend(loc='upper right', fontsize=10)\n",
    "\n",
    "# Definir rótulo do eixo x apenas para o último subplot\n",
    "axs[-1].set_xlabel(\"Tempo (intervalos de 5 minutos)\", fontsize=12)\n",
    "\n",
    "# Melhorar layout dos subplots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0033f038-db08-42d8-8862-0a6fd5affa5a",
   "metadata": {},
   "source": [
    "## Subamostragem de Estradas\n",
    "\n",
    "Para reduzir o tamanho do problema e tornar o treinamento mais rápido, trabalharemos com uma subamostra das 228 disponíveis no conjunto de dados. \n",
    "\n",
    "`sample_routes` contém os IDs das estradas selecionadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329e7f8f-32bb-4b93-8a49-f51926e76218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o número total de rotas no dataset e o número de rotas que queremos selecionar\n",
    "num_total_routes = 228  # Número total de rotas no dataset\n",
    "num_sample_routes = 60   # Número de rotas que queremos subamostrar\n",
    "\n",
    "# Gerando uma amostra aleatória de 'num_sample_routes' rotas a partir do total de rotas\n",
    "sample_routes = np.random.choice(num_total_routes, num_sample_routes, replace=False)\n",
    "\n",
    "\n",
    "route_distances = route_distances[np.ix_(sample_routes, sample_routes)] \n",
    "speeds_array = speeds_array[:, sample_routes]\n",
    "\n",
    "print(f\"route_distances shape={route_distances.shape}\")\n",
    "print(f\"speeds_array shape={speeds_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60518423-0c2a-41af-9798-ce89fa81f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de65b72b-9988-45e2-8b8d-b5089272a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o grafo diretamente da matriz de adjacência (distâncias subamostradas)\n",
    "G = nx.from_numpy_array(route_distances)\n",
    "\n",
    "# Plotando o grafo com as arestas ponderadas pelas distâncias\n",
    "pos = nx.spring_layout(G, seed=42)  # Layout do grafo\n",
    "edges = G.edges(data=True)\n",
    "weights = [1 / (w['weight'] + 1) for _, _, w in edges]  # Pesos das arestas\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "nx.draw(G, pos, node_size=50, edge_color=weights, edge_cmap=plt.cm.Blues)\n",
    "\n",
    "plt.title(f\"Grafo de {num_estacoes} Estações com Pesos Baseados nas Distâncias\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f1938-454f-4a55-90ca-e2c61b968e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o gráfico de matriz de correlação com legenda\n",
    "plt.figure(figsize=(15, 15))\n",
    "corr_matrix = np.corrcoef(speeds_array.T)\n",
    "\n",
    "# Plot da matriz de correlação\n",
    "cax = plt.matshow(corr_matrix)\n",
    "\n",
    "# Adicionar barra de cores (legenda)\n",
    "plt.colorbar(cax)\n",
    "\n",
    "# Definir rótulos para os eixos\n",
    "plt.xlabel(\"Número da estrada\")\n",
    "plt.ylabel(\"Número da estrada\")\n",
    "\n",
    "plt.title(\"Matriz de Correlação das Séries Temporais de Velocidade entre Estradas\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5662c11e-4829-45b8-895c-d0e45a90a684",
   "metadata": {},
   "source": [
    "## Spliting: Treino, validação e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd221124-469f-4e9e-b3de-68df004f0880",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, val_size = 0.6, 0.2\n",
    "\n",
    "\n",
    "def preprocess(data_array: np.ndarray, train_size: float, val_size: float):\n",
    "    \"\"\"Splits data into train/val/test sets and normalizes the data.\n",
    "\n",
    "    Args:\n",
    "        data_array: ndarray of shape `(num_time_steps, num_routes)`\n",
    "        train_size: A float value between 0.0 and 1.0 that represent the proportion of the dataset\n",
    "            to include in the train split.\n",
    "        val_size: A float value between 0.0 and 1.0 that represent the proportion of the dataset\n",
    "            to include in the validation split.\n",
    "\n",
    "    Returns:\n",
    "        `train_array`, `val_array`, `test_array`\n",
    "    \"\"\"\n",
    "\n",
    "    num_time_steps = data_array.shape[0]\n",
    "    num_train, num_val = (\n",
    "        int(num_time_steps * train_size),\n",
    "        int(num_time_steps * val_size),\n",
    "    )\n",
    "    train_array = data_array[:num_train]\n",
    "    mean, std = train_array.mean(axis=0), train_array.std(axis=0)\n",
    "\n",
    "    train_array = (train_array - mean) / std\n",
    "    val_array = (data_array[num_train : (num_train + num_val)] - mean) / std\n",
    "    test_array = (data_array[(num_train + num_val) :] - mean) / std\n",
    "\n",
    "    return train_array, val_array, test_array\n",
    "\n",
    "\n",
    "train_array, val_array, test_array = preprocess(speeds_array, train_size, val_size)\n",
    "\n",
    "print(f\"train set size: {train_array.shape}\")\n",
    "print(f\"validation set size: {val_array.shape}\")\n",
    "print(f\"test set size: {test_array.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a6724e-d432-4c42-9e78-9e4e5fa1c2da",
   "metadata": {},
   "source": [
    "|------dataset-------|   -> |--tr--|--val--|--ts--|   sem mudar a ordem!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedcb495-de54-42fd-9121-6c0c28d7713e",
   "metadata": {},
   "source": [
    "## Criação de Datasets no TensorFlow\n",
    "\n",
    "Usamos a função `timeseries_dataset_from_array()` da Keras para criar os datasets para o nosso problema de previsão de tráfego. A função `create_tf_dataset()` recebe como entrada um `numpy.ndarray` e retorna um `tf.data.Dataset`. Nessa função, o argumento `input_sequence_length` é definido como **50**, representando o comprimento da sequência de entrada, e o argumento `forecast_horizon` é definido como **5**, representando o horizonte de previsão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6820d6b6-7dcb-4754-825b-13f185a5077c",
   "metadata": {},
   "source": [
    "v1 ---------------|ooooooo|--------x-------  \n",
    "v2 ---------------|ooooooo|--------x-------  \n",
    "v3 ---------------|ooooooo|--------x-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df23053-d6c4-4fae-afeb-96ae6943a905",
   "metadata": {},
   "source": [
    "## Nossos parâmetros\n",
    "\n",
    "No nosso exemplo, usamos os seguintes parâmetros:\n",
    "- `input_sequence_length = 50`: Usamos os últimos 50 valores de velocidade de cada estrada como entrada.\n",
    "- `forecast_horizon = 5`: Prevemos a velocidade para os 30 próximos passos de tempo.\n",
    "- `batch_size = 64`: Cada lote de dados terá 64 amostras.\n",
    "- `multi_horizon = False`: Fazemos a previsão apenas para o último passo de tempo t+T+5.\n",
    "\n",
    "A entrada do tensor em cada batch terá a forma `(batch_size, input_sequence_length, num_routes, 1)`, onde a última dimensão é 1, para representar uma única série temporal por estrada. Caso quiséssemos usar várias séries temporais (como temperatura ou outro dado), a última dimensão poderia ser maior. Neste exemplo, a previsão é feita somente com base nos valores históricos de velocidade.\n",
    "\n",
    "A função `create_tf_dataset()` foi usada para criar os datasets de treino, validação e teste:\n",
    "\n",
    "- `train_dataset` e `val_dataset` são criados a partir de `train_array` e `val_array`, respectivamente.\n",
    "- `test_dataset` é criado a partir de `test_array`, com um `batch_size` igual ao número total de amostras de teste, sem embaralhamento (`shuffle=False`) e com `multi_horizon=True` ou `multi_horizon=False`, dependendo do objetivo da previsão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d21639a-5010-4721-af56-c92aea0aed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "\n",
    "batch_size = 64\n",
    "input_sequence_length = 50\n",
    "forecast_horizon = 5\n",
    "multi_horizon = False\n",
    "\n",
    "\n",
    "def create_tf_dataset(\n",
    "    data_array: np.ndarray,\n",
    "    input_sequence_length: int,\n",
    "    forecast_horizon: int,\n",
    "    batch_size: int = 32,\n",
    "    shuffle=True,\n",
    "    multi_horizon=True,\n",
    "):\n",
    "    \"\"\"Creates tensorflow dataset from numpy array.\n",
    "\n",
    "    This function creates a dataset where each element is a tuple `(inputs, targets)`.\n",
    "    `inputs` is a Tensor\n",
    "    of shape `(batch_size, input_sequence_length, num_routes, 1)` containing\n",
    "    the `input_sequence_length` past values of the timeseries for each node.\n",
    "    `targets` is a Tensor of shape `(batch_size, forecast_horizon, num_routes)`\n",
    "    containing the `forecast_horizon`\n",
    "    future values of the timeseries for each node.\n",
    "\n",
    "    Args:\n",
    "        data_array: np.ndarray with shape `(num_time_steps, num_routes)`\n",
    "        input_sequence_length: Length of the input sequence (in number of timesteps).\n",
    "        forecast_horizon: If `multi_horizon=True`, the target will be the values of the timeseries for 1 to\n",
    "            `forecast_horizon` timesteps ahead. If `multi_horizon=False`, the target will be the value of the\n",
    "            timeseries `forecast_horizon` steps ahead (only one value).\n",
    "        batch_size: Number of timeseries samples in each batch.\n",
    "        shuffle: Whether to shuffle output samples, or instead draw them in chronological order.\n",
    "        multi_horizon: See `forecast_horizon`.\n",
    "\n",
    "    Returns:\n",
    "        A tf.data.Dataset instance.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = timeseries_dataset_from_array(\n",
    "        np.expand_dims(data_array[:-forecast_horizon], axis=-1),\n",
    "        None,\n",
    "        sequence_length=input_sequence_length,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        # sequence_stride=1,\n",
    "    )# Por padrão o stride=1\n",
    "\n",
    "    target_offset = (\n",
    "        input_sequence_length\n",
    "        if multi_horizon\n",
    "        else input_sequence_length + forecast_horizon - 1\n",
    "    )\n",
    "    target_seq_length = forecast_horizon if multi_horizon else 1\n",
    "    targets = timeseries_dataset_from_array(\n",
    "        data_array[target_offset:],\n",
    "        None,\n",
    "        sequence_length=target_seq_length,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "    ) # Por padrão o stride=1\n",
    "\n",
    "    dataset = tf.data.Dataset.zip((inputs, targets))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(100)\n",
    "\n",
    "    return dataset.prefetch(16).cache()\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = (\n",
    "    create_tf_dataset(data_array, input_sequence_length, forecast_horizon, batch_size)\n",
    "    for data_array in [train_array, val_array]\n",
    ")\n",
    "\n",
    "test_dataset = create_tf_dataset(\n",
    "    test_array,\n",
    "    input_sequence_length,\n",
    "    forecast_horizon,\n",
    "    batch_size=test_array.shape[0],\n",
    "    shuffle=False,\n",
    "    multi_horizon=multi_horizon,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059949e3-f364-4183-b86d-33c6b083fed0",
   "metadata": {},
   "source": [
    "### multi_horizon\n",
    "\n",
    "O argumento `multi_horizon` determina como os alvos (targets) serão gerados:\n",
    "- Se `multi_horizon=True`, o modelo fará uma previsão para os passos de tempo t+T+1, t+T+2 ... t+T+5. Portanto, o alvo terá a forma `(batch_size, forecast_horizon, num_routes)`, onde `forecast_horizon` será igual a 5.\n",
    "- Se `multi_horizon=False`, o modelo fará a previsão apenas para o último passo de tempo t+T+5. Nesse caso, o alvo terá a forma `(batch_size, 1, num_routes)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57935289-2cb5-4f19-a97a-f74b44fe529a",
   "metadata": {},
   "source": [
    "## Séries de entrada e saída do modelo\n",
    "\n",
    "Abaixo exibimos como são as séries que serão usadas como treino e teste para cada nó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10380f00-64c5-4af9-ac46-6fecea0440cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_inputs, batch_targets in train_dataset.take(1): ## take(i) retorna o batch i\n",
    "    batch_inputs = batch_inputs.numpy()\n",
    "    batch_targets = batch_targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c0dfd-15ce-4d89-b7f6-d82076b2bfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc135ad0-0f72-4a62-b900-f00bb7e934b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6de501-17d9-468a-9a51-6b8606c244c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar algumas estradas e exibir suas séries temporais\n",
    "selected_routes = [0, 1, 2]  # Escolhendo três rotas como exemplo\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for route in selected_routes:\n",
    "    plt.plot(batch_inputs[0, :, route, 0], label=f'Estrada {route} (Entrada)')\n",
    "    # plt.plot(batch_inputs[0, :, :, 0], )\n",
    "\n",
    "\n",
    "plt.title(\"Séries Temporais de Velocidade - Entradas\")\n",
    "plt.xlabel(\"Passos de Tempo\")\n",
    "plt.ylabel(\"Velocidade\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plotar as previsões (targets)\n",
    "plt.figure(figsize=(12, 6))\n",
    "for route in selected_routes:\n",
    "    # plt.plot(batch_targets[0, :, :],)\n",
    "    plt.plot(batch_targets[0, :, route], label=f'Estrada {route} (Alvo)')\n",
    "\n",
    "\n",
    "plt.title(\"Séries Temporais de Velocidade - Alvos (Previsão)\")\n",
    "plt.xlabel(\"Passos de Tempo\")\n",
    "plt.ylabel(\"Velocidade\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f578743-4232-4bd2-ade1-9894de5b0fc6",
   "metadata": {},
   "source": [
    "## Grafo das Estradas\n",
    "\n",
    "Como mencionado anteriormente, assumimos que os segmentos de estrada formam um grafo. O conjunto de dados **PeMSD7** contém as distâncias entre os segmentos de estrada. O próximo passo é criar a **matriz de adjacência** do grafo a partir dessas distâncias.\n",
    "\n",
    "Assumimos que existe uma **aresta** entre dois nós no grafo se a distância entre as respectivas estradas for menor que um determinado **limite** (threshold).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31e17b7-7411-4849-a948-65a6049f57ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa022283-6fcc-41e2-b263-f1116e9bf9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_adjacency_matrix(\n",
    "    route_distances: np.ndarray, sigma2: float, epsilon: float\n",
    "):\n",
    "    \"\"\"Computes the adjacency matrix from distances matrix.\n",
    "\n",
    "    It uses the formula in https://github.com/VeritasYin/STGCN_IJCAI-18#data-preprocessing to\n",
    "    compute an adjacency matrix from the distance matrix.\n",
    "    The implementation follows that paper.\n",
    "\n",
    "    Args:\n",
    "        route_distances: np.ndarray of shape `(num_routes, num_routes)`. Entry `i,j` of this array is the\n",
    "            distance between roads `i,j`.\n",
    "        sigma2: Determines the width of the Gaussian kernel applied to the square distances matrix.\n",
    "        epsilon: A threshold specifying if there is an edge between two nodes. Specifically, `A[i,j]=1`\n",
    "            if `np.exp(-w2[i,j] / sigma2) >= epsilon` and `A[i,j]=0` otherwise, where `A` is the adjacency\n",
    "            matrix and `w2=route_distances * route_distances`\n",
    "\n",
    "    Returns:\n",
    "        A boolean graph adjacency matrix.\n",
    "    \"\"\"\n",
    "    num_routes = route_distances.shape[0]\n",
    "    route_distances = route_distances / 10000.0\n",
    "    w2, w_mask = (\n",
    "        route_distances * route_distances,\n",
    "        np.ones([num_routes, num_routes]) - np.identity(num_routes),\n",
    "    )\n",
    "    return (np.exp(-w2 / sigma2) >= epsilon) * w_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50033f6-2ec2-42a5-aea7-58201b2a3451",
   "metadata": {},
   "source": [
    "### Explicação de `compute_adjacency_matrix`\n",
    "\n",
    "A função `compute_adjacency_matrix` calcula a **matriz de adjacência** a partir de uma matriz de distâncias entre estradas, aplicando uma fórmula baseada no trabalho de Yu et al., 2018. Ela utiliza um **kernel Gaussiano** para determinar se há uma conexão (aresta) entre dois nós (estradas) no grafo.\n",
    "\n",
    "### Argumentos:\n",
    "1. **`route_distances`**: Um array NumPy com forma `(num_routes, num_routes)` que contém as distâncias entre as estradas. Cada entrada `i,j` representa a distância entre a estrada `i` e a estrada `j`.\n",
    "2. **`sigma2`**: Um parâmetro que controla a largura do **kernel Gaussiano** aplicado às distâncias quadradas. Esse parâmetro influencia como a distância afeta a criação de arestas.\n",
    "3. **`epsilon`**: Um **limite** que determina se uma aresta será criada entre dois nós. Especificamente, se a função Gaussiana aplicada às distâncias for maior ou igual a `epsilon`, uma aresta será criada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d71caa0-9832-4260-8a4d-0c152b232f22",
   "metadata": {},
   "source": [
    "### Passo a Passo:\n",
    "\n",
    "1. **`num_routes = route_distances.shape[0]`**: \n",
    "   - Calcula o número de estradas a partir da dimensão da matriz de distâncias.\n",
    "\n",
    "2. **`route_distances = route_distances / 10000.0`**: \n",
    "   - Normaliza os valores da matriz de distâncias, dividindo cada valor por 10.000. Isso ajuda a evitar problemas numéricos durante o cálculo exponencial.\n",
    "\n",
    "3. **`w2 = route_distances * route_distances`**:\n",
    "   - Calcula a matriz de distâncias ao quadrado. O valor para cada estrada `i` e `j` é o quadrado da distância entre elas: `w2[i,j] = route_distances[i,j]^2`.\n",
    "\n",
    "4. **`w_mask = np.ones([num_routes, num_routes]) - np.identity(num_routes)`**:\n",
    "   - Cria uma **máscara** para remover as auto-conexões. Essa matriz contém `1`s em todas as posições exceto na diagonal principal (que são `0`s), pois não queremos criar arestas entre um nó e ele mesmo.\n",
    "\n",
    "5. **`np.exp(-w2 / sigma2)`**:\n",
    "   - Aplica a função Gaussiana às distâncias quadradas. A fórmula usada é:\n",
    "     $$\n",
    "     \\exp\\left(-\\frac{w^2[i,j]}{\\sigma^2}\\right)\n",
    "     $$\n",
    "     Essa função decai exponencialmente com a distância: distâncias pequenas produzem valores próximos de 1 (alta conexão), e distâncias grandes resultam em valores próximos de 0.\n",
    "\n",
    "6. **`(np.exp(-w2 / sigma2) >= epsilon)`**:\n",
    "   - Verifica se o valor da função Gaussiana é maior ou igual ao limite `epsilon`. Se for, uma aresta é criada entre os nós (estradas) `i` e `j`.\n",
    "\n",
    "7. **`* w_mask`**:\n",
    "   - Multiplica pela máscara para garantir que não existam arestas que conectem uma estrada a ela mesma. As auto-conexões são removidas definindo a diagonal como `0`.\n",
    "\n",
    "### Retorno:\n",
    "- A função retorna uma **matriz booleana de adjacência**, onde:\n",
    "  - `True`: Há uma aresta entre as estradas (nós),\n",
    "  - `False`: Não há uma aresta entre as estradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c2d7d-fc78-469b-9712-34c7efdaa4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os parâmetros\n",
    "w2 = np.linspace(-10, 10, 100)  # Criando um intervalo de valores para w2\n",
    "sigma2 = 2.0  # Definindo o valor de sigma2\n",
    "\n",
    "# Calculando a função\n",
    "y = np.exp(-w2**2 / sigma2)\n",
    "\n",
    "# Plotando o gráfico\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(w2, y, label=r'$e^{-w^2/\\sigma^2}$')\n",
    "plt.title(r'Plot of $e^{-w^2/\\sigma^2}$')\n",
    "plt.xlabel(r'$w^2$')\n",
    "plt.ylabel(r'$e^{-w^2/\\sigma^2}$')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0a38cb-661f-4d5a-9c98-b856a71dc489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nosso gráfo é estático!!! logo só precisamos calcular uma vez\n",
    "\n",
    "class GraphInfo:\n",
    "    def __init__(self, edges: typing.Tuple[list, list], num_nodes: int):\n",
    "        self.edges = edges\n",
    "        self.num_nodes = num_nodes\n",
    "\n",
    "\n",
    "sigma2 = .5\n",
    "epsilon = 0.5\n",
    "adjacency_matrix = compute_adjacency_matrix(route_distances, sigma2, epsilon)\n",
    "node_indices, neighbor_indices = np.where(adjacency_matrix == 1)\n",
    "graph = GraphInfo(\n",
    "    edges=(node_indices.tolist(), neighbor_indices.tolist()),\n",
    "    num_nodes=adjacency_matrix.shape[0],\n",
    ")\n",
    "print(f\"number of nodes: {graph.num_nodes}, number of edges: {len(graph.edges[0])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc36c2-c3ae-4c50-a45d-f2369a99b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANTES\n",
    "plt.imshow(route_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9329e38-8a28-446f-8115-d3f3d93c728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPOIS\n",
    "plt.imshow(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5cef3d-8ce8-4b3a-9d6a-0656b55fba06",
   "metadata": {},
   "source": [
    "## Convoluções em Grafos como Message Passing\n",
    "\n",
    "Cada camada de convolução em grafos processa os **vetores de características** dos nós provenientes da camada anterior (ou, no caso da primeira camada, os vetores de entrada), gerando novos vetores de saída para cada nó. O princípio fundamental por trás da convolução em grafos é o **Message Passing**, onde cada nó atualiza seu vetor de características ao \"agregar\" informações dos seus nós vizinhos.\n",
    "\n",
    "### Como funciona\n",
    "\n",
    "O processo de convolução pode ser visto como um mecanismo de **propagação de mensagens** entre os nós, onde a informação flui de nó para nó, permitindo que a rede aprenda padrões tanto estruturais quanto de características nos dados.\n",
    "\n",
    "A imagem abaixo ilustra esse processo de \"passagem de mensagem\" em uma camada de convolução em grafos:\n",
    "\n",
    "![message](GCN_conv_layer_message_pass_1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b463f4-11c3-42af-87fe-bc7828a8bcb6",
   "metadata": {},
   "source": [
    "No esquema acima, o vetor do nó A, denotado por $x_A$, é agregado aos vetores de seus vizinhos, $x_B$ e $x_C$. Esse vetor agregado é então transformado/atualizado para formar o novo vetor do nó A na próxima camada, denotado por $h_A$. Esse procedimento é aplicado a cada nó do grafo.\n",
    "\n",
    "Esse processo pode ser descrito em duas etapas:\n",
    "\n",
    "1. **Agregação**: O nó A coleta as informações de seus vizinhos (nós B e C), criando um vetor agregado.\n",
    "2. **Transformação**: O vetor agregado é transformado através de uma função (linear ou não-linear), resultando no novo vetor do nó A, $h_A$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a8fe68-3767-4497-b355-07c44829b095",
   "metadata": {},
   "source": [
    "## Como isso se relaciona com a última aula?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923906d-cbbe-4601-8416-322a712acbb8",
   "metadata": {},
   "source": [
    "O procedimento de convolução em grafos é frequentemente chamado de **message passing** (passagem de mensagens), pois cada nó \"envia\" seu vetor de características para seus vizinhos com o objetivo de atualizar os vetores desses nós. A \"mensagem\" de cada nó é representada pelo vetor associado a ele.\n",
    "\n",
    "Agora, como exatamente uma GCN realiza a agregação e atualização? Para responder a isso, vamos analisar a matemática por trás da camada de convolução em grafos. Seja $X \\in \\mathbb{R}^{n \\times d}$ as características associadas aos nós, onde $n$ é o número de nós e $d$ é o número de características. Ou seja, a linha $i$ de $X$ armazena as características do nó $i$. Seja $A$ a matriz de adjacência do grafo, onde:\n",
    "\n",
    "$$\n",
    "A_{i,j} = \n",
    "\\begin{cases}\n",
    "1, & \\text{se houver uma aresta entre os nós } i \\text{ e } j \\\\\n",
    "0, & \\text{caso contrário}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Como vimos na outra aula**, as matrizes $X$ e $A$ são as duas peças de dados necessárias como entrada para uma GCN aplicada a um grafo. A camada de convolução em grafos pode ser expressa como uma função que aceita essas duas entradas e retorna uma matriz que representa os vetores atualizados de cada nó. Esta função é dada por:\n",
    "\n",
    "$$\n",
    "f(X, A) := \\sigma(D^{-1/2}(A + I)D^{-1/2}XW)\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "- $A \\in \\mathbb{R}^{n \\times n}$: Matriz de adjacência.\n",
    "- $I \\in \\mathbb{R}^{n \\times n}$: Matriz identidade.\n",
    "- $D \\in \\mathbb{R}^{n \\times n}$: Matriz de grau de $A + I$.\n",
    "- $X \\in \\mathbb{R}^{n \\times d}$: Matriz de entrada (os vetores de características dos nós).\n",
    "- $W \\in \\mathbb{R}^{d \\times w}$: Pesos da camada.\n",
    "- $\\sigma(\\cdot)$: Função de ativação (ex: ReLU).\n",
    "\n",
    "\n",
    "![equation](GCN_layer_equation_annotated.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c3962b-e6b8-4932-803e-0704113e3cc0",
   "metadata": {},
   "source": [
    "### Entendendo cada multiplicação de matrizes:\n",
    "\n",
    "1. **A + I**: Esta operação adiciona 1s à diagonal da matriz de adjacência. Isso é equivalente a adicionar self-loops (auto-conexões) ao grafo, garantindo que cada nó também passe sua própria mensagem para si mesmo durante o processo de agregação.\n",
    "\n",
    "2. **D**: A matriz de grau de $A + I$. É uma matriz diagonal onde o elemento $d_{i,i}$ armazena o número total de nós vizinhos do nó $i$ (incluindo ele mesmo, após a adição dos self-loops).\n",
    "\n",
    "3. **D^{-1/2}**: O inverso da raiz quadrada da matriz de grau. Esta matriz é usada para normalizar a matriz de adjacência. A multiplicação $D^{-1/2}(A + I)D^{-1/2}$ normaliza o grafo, garantindo que os valores nas arestas sejam ajustados proporcionalmente ao grau dos nós.\n",
    "\n",
    "4. **Ã**: Após a normalização, denotamos a nova matriz como $\\tilde{A} = D^{-1/2}(A + I)D^{-1/2}$. Isso assegura que $\\tilde{A}_{i,j} \\neq 0$ apenas se houver uma aresta entre os nós $i$ e $j$.\n",
    "\n",
    "Agora podemos simplificar a função da camada de convolução em grafos **(como na última aula)**:\n",
    "\n",
    "$$\n",
    "f(X, A) := \\sigma(\\tilde{A} X W)\n",
    "$$\n",
    "\n",
    "### Agregação e Passagem de Mensagens\n",
    "\n",
    "A multiplicação $\\tilde{A} X$ realiza a função de agregação ou **message passing**. Para cada nó $i$, os vetores das características dos nós vizinhos são combinados (somados) com pesos determinados pela matriz normalizada $\\tilde{A}$.\n",
    "\n",
    "![aggreg](GCN_aggregation_matrices.png)\n",
    "\n",
    "\n",
    "Seja $\\bar{x}_i$ o vetor agregado no nó $i$. Ele pode ser expresso como:\n",
    "\n",
    "$$\n",
    "\\bar{x}_i = \\sum_{j=1}^{n} \\tilde{a}_{i,j} x_j = \\sum_{j \\in Neigh(i)} \\frac{1}{\\sqrt{d_i d_j}} x_j\n",
    "$$\n",
    "\n",
    "Aqui, o vetor no nó $i$ é uma soma ponderada dos vetores dos nós vizinhos, com os pesos armazenados na matriz $\\tilde{A}$. Esses pesos não são aprendidos, mas determinados exclusivamente com base na estrutura do grafo.\n",
    "\n",
    "### Atualização com Pesos Aprendidos\n",
    "\n",
    "Os pesos aprendidos, que são os parâmetros do modelo, estão armazenados na matriz $W$. A multiplicação $(\\tilde{A} X) W$ aplica esses pesos aos vetores agregados para atualizar as características de cada nó.\n",
    "\n",
    "Finalmente, esses vetores atualizados são passados por uma função de ativação $\\sigma$, que introduz não-linearidade no modelo.\n",
    "\n",
    "![update](GCN_update_matrices.png)\n",
    "\n",
    "### Múltiplas Camadas de Convolução em Grafos\n",
    "\n",
    "Até agora, discutimos uma única camada de convolução em grafos. No entanto, podemos empilhar várias camadas de convolução. A saída de uma camada serve como entrada para a próxima. Matematicamente, podemos expressar isso da seguinte forma:\n",
    "\n",
    "$$\n",
    "H_1 := f_{W_1}(X, A), \\quad H_2 := f_{W_2}(H_1, A), \\quad H_3 := f_{W_3}(H_2, A)\n",
    "$$\n",
    "\n",
    "Onde $H_1$, $H_2$, e $H_3$ são os vetores incorporados dos nós nas camadas 1, 2 e 3, respectivamente. As matrizes $W_1$, $W_2$, e $W_3$ são as matrizes de pesos que parametrizam cada camada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cc38ec-f463-4e9d-a37b-723b2b756de3",
   "metadata": {},
   "source": [
    "### Agregação Personalizada\n",
    "\n",
    "Embora a agregação na camada de convolução em grafos, conforme descrita anteriormente, seja frequentemente realizada como uma **soma ponderada** dos vetores dos nós vizinhos, essa não é a única forma de agregação. Existem diversas estratégias de agregação que podem ser usadas, dependendo da natureza do problema ou das características específicas do grafo.\n",
    "\n",
    "#### Exemplos de Agregações Alternativas:\n",
    "\n",
    "1. **Média**: Em vez de somar os vetores dos nós vizinhos, podemos calcular a **média**. Isso pode ser útil para suavizar as diferenças entre os vetores vizinhos, normalizando a contribuição de cada um.\n",
    "   $$\n",
    "   \\bar{x}_i = \\frac{1}{|Neigh(i)|} \\sum_{j \\in Neigh(i)} x_j\n",
    "   $$\n",
    "\n",
    "2. **Agregação Máxima**: Em alguns cenários, podemos usar a **agregação máxima**, onde tomamos o valor máximo entre os vetores dos vizinhos, aplicando uma espécie de filtro que seleciona as características mais \"fortes\" ou dominantes.\n",
    "   $$\n",
    "   \\bar{x}_i = \\max_{j \\in Neigh(i)} x_j\n",
    "   $$\n",
    "\n",
    "3. **Concatenar**: Outra forma é **concatenar** os vetores dos vizinhos, em vez de somá-los ou tirar a média. Esse método preserva mais informações dos nós vizinhos, mas pode aumentar consideravelmente a dimensionalidade dos vetores.\n",
    "   $$\n",
    "   \\bar{x}_i = \\text{concat}(x_j \\text{ para } j \\in Neigh(i))\n",
    "   $$\n",
    "\n",
    "4. **Atendimento por Atenção (Attention)**: Em modelos mais avançados, como o **Graph Attention Network (GAT)**, a agregação pode ser feita usando um mecanismo de atenção, onde cada vizinho contribui com um peso aprendido dinâmicamente, permitindo que o modelo ajuste a importância de cada vizinho em tempo real.\n",
    "   $$\n",
    "   \\bar{x}_i = \\sum_{j \\in Neigh(i)} \\alpha_{ij} x_j\n",
    "   $$\n",
    "   Onde os pesos $\\alpha_{ij}$ são calculados com base em um mecanismo de atenção.\n",
    "\n",
    "Portanto, a operação de agregação pode ser flexível e adaptável às necessidades do modelo, permitindo diferentes formas de capturar a estrutura e as características dos nós e seus vizinhos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e9cff0-dda5-461b-90d1-a8f084f50272",
   "metadata": {},
   "source": [
    "## Voltando ao problema..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfb52c6-1083-4b76-b26f-4cc549bf75c8",
   "metadata": {},
   "source": [
    "### Arquitetura da GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6aa0b2-01f8-4757-824d-8f5a96bf8ca8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "A arquitetura da rede fica como abaixo. As representações dos nós são calculadas na função `self.compute_nodes_representation()`, onde as características de entrada são multiplicadas pelos pesos armazenados em `self.weight`. \n",
    "\n",
    "As mensagens agregadas dos vizinhos são calculadas na função `self.compute_aggregated_messages()`, onde as representações dos vizinhos são primeiramente agregadas e, em seguida, os resultados são multiplicados por `self.weight`.\n",
    "\n",
    "A saída final da camada é calculada na função `self.update()`, combinando as representações dos nós com as mensagens agregadas dos vizinhos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6741308b-8119-4ab6-bf61-e742f4389cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConv(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_feat, # quantas series temporais\n",
    "        out_feat,\n",
    "        graph_info: GraphInfo,\n",
    "        aggregation_type=\"mean\",\n",
    "        combination_type=\"concat\",\n",
    "        activation: typing.Optional[str] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.in_feat = in_feat\n",
    "        self.out_feat = out_feat\n",
    "        self.graph_info = graph_info\n",
    "        self.aggregation_type = aggregation_type\n",
    "        self.combination_type = combination_type\n",
    "        self.weight = tf.Variable(\n",
    "            initial_value=keras.initializers.glorot_uniform()(\n",
    "                shape=(in_feat, out_feat), dtype=\"float32\"\n",
    "            ),\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.activation = layers.Activation(activation)\n",
    "\n",
    "    def aggregate(self, neighbour_representations: tf.Tensor):\n",
    "        aggregation_func = {\n",
    "            \"sum\": tf.math.unsorted_segment_sum,\n",
    "            \"mean\": tf.math.unsorted_segment_mean,\n",
    "            \"max\": tf.math.unsorted_segment_max,\n",
    "        }.get(self.aggregation_type)\n",
    "\n",
    "        if aggregation_func:\n",
    "            return aggregation_func(\n",
    "                neighbour_representations,\n",
    "                self.graph_info.edges[0],\n",
    "                num_segments=self.graph_info.num_nodes,\n",
    "            )\n",
    "\n",
    "        raise ValueError(f\"Invalid aggregation type: {self.aggregation_type}\")\n",
    "\n",
    "    def compute_nodes_representation(self, features: tf.Tensor):\n",
    "        \"\"\"Computes each node's representation.\n",
    "\n",
    "        The nodes' representations are obtained by multiplying the features tensor with\n",
    "        `self.weight`. Note that\n",
    "        `self.weight` has shape `(in_feat, out_feat)`.\n",
    "\n",
    "        Args:\n",
    "            features: Tensor of shape `(num_nodes, batch_size, input_seq_len, in_feat)`\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape `(num_nodes, batch_size, input_seq_len, out_feat)`\n",
    "        \"\"\"\n",
    "        return tf.matmul(features, self.weight)\n",
    "\n",
    "    def compute_aggregated_messages(self, features: tf.Tensor):\n",
    "        neighbour_representations = tf.gather(features, self.graph_info.edges[1])\n",
    "        aggregated_messages = self.aggregate(neighbour_representations)\n",
    "        return tf.matmul(aggregated_messages, self.weight)\n",
    "\n",
    "    def update(self, nodes_representation: tf.Tensor, aggregated_messages: tf.Tensor):\n",
    "        if self.combination_type == \"concat\":\n",
    "            h = tf.concat([nodes_representation, aggregated_messages], axis=-1)\n",
    "        elif self.combination_type == \"add\":\n",
    "            h = nodes_representation + aggregated_messages\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid combination type: {self.combination_type}.\")\n",
    "\n",
    "        return self.activation(h)\n",
    "\n",
    "    def call(self, features: tf.Tensor):\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Args:\n",
    "            features: tensor of shape `(num_nodes, batch_size, input_seq_len, in_feat)`\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape `(num_nodes, batch_size, input_seq_len, out_feat)`\n",
    "        \"\"\"\n",
    "        nodes_representation = self.compute_nodes_representation(features)\n",
    "        aggregated_messages = self.compute_aggregated_messages(features)\n",
    "        return self.update(nodes_representation, aggregated_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506a3b82-96ac-4542-aebe-c5821be246ba",
   "metadata": {},
   "source": [
    "#### Etapa de combinação com concatenação\n",
    "\n",
    "Isso cria um novo vetor de características para cada nó que inclui tanto a informação original do nó quanto as mensagens dos vizinhos de forma explícita, aumentando o número total de dimensões.\n",
    "\n",
    "**Benefício:** A concatenação preserva as informações originais e as mensagens agregadas separadamente, permitindo que camadas posteriores aprendam como combinar essas informações de maneira mais rica.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd0fae1-1578-4c1c-9a5c-761549ba3cdd",
   "metadata": {},
   "source": [
    "### Arquitetura da LSTM+GC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c42b8fa-766f-44f7-908b-49ccf4e550a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMGC(layers.Layer):\n",
    "    \"\"\"Layer comprising a convolution layer followed by LSTM and dense layers.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_feat,\n",
    "        out_feat,\n",
    "        lstm_units: int,\n",
    "        input_seq_len: int,\n",
    "        output_seq_len: int,\n",
    "        graph_info: GraphInfo,\n",
    "        graph_conv_params: typing.Optional[dict] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # graph conv layer\n",
    "        if graph_conv_params is None:\n",
    "            graph_conv_params = {\n",
    "                \"aggregation_type\": \"mean\",\n",
    "                \"combination_type\": \"concat\",\n",
    "                \"activation\": None,\n",
    "            }\n",
    "        self.graph_conv = GraphConv(in_feat, out_feat, graph_info, **graph_conv_params)\n",
    "\n",
    "        self.lstm = layers.LSTM(lstm_units, activation=\"relu\")\n",
    "        self.dense = layers.Dense(output_seq_len)\n",
    "\n",
    "        self.input_seq_len, self.output_seq_len = input_seq_len, output_seq_len\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Args:\n",
    "            inputs: tf.Tensor of shape `(batch_size, input_seq_len, num_nodes, in_feat)`\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape `(batch_size, output_seq_len, num_nodes)`.\n",
    "        \"\"\"\n",
    "\n",
    "        # convert shape to  (num_nodes, batch_size, input_seq_len, in_feat)\n",
    "        inputs = tf.transpose(inputs, [2, 0, 1, 3])\n",
    "\n",
    "        gcn_out = self.graph_conv(\n",
    "            inputs\n",
    "        )  # gcn_out has shape: (num_nodes, batch_size, input_seq_len, out_feat)\n",
    "        shape = tf.shape(gcn_out)\n",
    "        num_nodes, batch_size, input_seq_len, out_feat = (\n",
    "            shape[0],\n",
    "            shape[1],\n",
    "            shape[2],\n",
    "            shape[3],\n",
    "        )\n",
    "\n",
    "        # LSTM takes only 3D tensors as input\n",
    "        gcn_out = tf.reshape(gcn_out, (batch_size * num_nodes, input_seq_len, out_feat))\n",
    "        lstm_out = self.lstm(\n",
    "            gcn_out\n",
    "        )  # lstm_out has shape: (batch_size * num_nodes, lstm_units)\n",
    "\n",
    "        dense_output = self.dense(\n",
    "            lstm_out\n",
    "        )  # dense_output has shape: (batch_size * num_nodes, output_seq_len)\n",
    "        output = tf.reshape(dense_output, (num_nodes, batch_size, self.output_seq_len))\n",
    "        return tf.transpose(\n",
    "            output, [1, 2, 0]\n",
    "        )  # returns Tensor of shape (batch_size, output_seq_len, num_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539e288b-7143-41ec-93b4-89f628c7f6e5",
   "metadata": {},
   "source": [
    "### Entendendo a LSTM no Grafo\n",
    "\n",
    "A camada **LSTMGC** combina convoluções em grafos com uma camada LSTM para capturar tanto as **dependências espaciais** (estrutura do grafo) quanto as **temporais** (evolução das características ao longo do tempo). Abaixo está o detalhamento de como cada parte do processo funciona:\n",
    "\n",
    "1. **Convolução em Grafos (`GraphConv`)**:\n",
    "   - A camada de convolução em grafos processa as entradas de cada nó, agregando informações dos nós vizinhos de acordo com a estrutura do grafo. Isso permite que as características dos nós sejam atualizadas com base nas interações espaciais com seus vizinhos. \n",
    "   - A saída da convolução tem a forma `(num_nodes, batch_size, input_seq_len, out_feat)`, onde:\n",
    "     - **`num_nodes`**: O número de nós no grafo.\n",
    "     - **`batch_size`**: O número de amostras processadas simultaneamente.\n",
    "     - **`input_seq_len`**: O comprimento da sequência temporal de entrada.\n",
    "     - **`out_feat`**: O número de características de saída por nó, atualizado pela convolução.\n",
    "\n",
    "2. **Camada LSTM**:\n",
    "   - A LSTM captura as **dependências temporais** de cada nó individualmente. Como a LSTM requer uma entrada tridimensional, o tensor de saída da convolução em grafos é reestruturado para ter a forma `(batch_size * num_nodes, input_seq_len, out_feat)`, combinando o número de nós e o tamanho do batch.\n",
    "   - A LSTM processa as sequências temporais de características de cada nó, aprendendo como elas mudam ao longo do tempo, e gera uma saída de forma `(batch_size * num_nodes, lstm_units)`, onde **`lstm_units`** define o número de unidades internas da LSTM.\n",
    "\n",
    "3. **Camada Densa**:\n",
    "   - A saída da LSTM é então passada por uma camada densa que transforma esses vetores de características em previsões temporais. A camada densa ajusta a dimensionalidade para a forma `(batch_size * num_nodes, output_seq_len)`, onde **`output_seq_len`** representa o número de passos temporais previstos para cada nó.\n",
    "\n",
    "4. **Reshape Final**:\n",
    "   - O tensor é reestruturado novamente para a forma `(batch_size, output_seq_len, num_nodes)`, organizando as previsões temporais por nó, de forma que o modelo forneça uma previsão de sequência de tempo para cada nó no grafo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c4a9a0-9cdf-47c6-9bc3-3700b083f5ad",
   "metadata": {},
   "source": [
    "## Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3bd32a-c047-4eed-9021-7caa4e476f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_feat = 1\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "input_sequence_length = 50\n",
    "forecast_horizon = 5\n",
    "multi_horizon = False\n",
    "out_feat = 10\n",
    "lstm_units = 64\n",
    "graph_conv_params = {\n",
    "    \"aggregation_type\": \"mean\",\n",
    "    \"combination_type\": \"concat\",\n",
    "    \"activation\": None,\n",
    "}\n",
    "\n",
    "st_gcn = LSTMGC(\n",
    "    in_feat,\n",
    "    out_feat,\n",
    "    lstm_units,\n",
    "    input_sequence_length,\n",
    "    forecast_horizon,\n",
    "    graph,\n",
    "    graph_conv_params,\n",
    ")\n",
    "inputs = layers.Input((input_sequence_length, graph.num_nodes, in_feat))\n",
    "outputs = st_gcn(inputs)\n",
    "\n",
    "model = keras.models.Model(inputs, outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=0.0002),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62bb0c7-0aa5-41d1-be5c-a475c9437582",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a954471-5d6b-432f-9249-af7070863606",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y = next(test_dataset.as_numpy_iterator())\n",
    "y_pred = model.predict(x_test)\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.plot(y[:, 0, 0])\n",
    "plt.plot(y_pred[:, 0, 0])\n",
    "plt.legend([\"actual\", \"forecast\"])\n",
    "\n",
    "naive_mse, model_mse = (\n",
    "    np.square(x_test[:, -1, :, 0] - y[:, 0, :]).mean(),\n",
    "    np.square(y_pred[:, 0, :] - y[:, 0, :]).mean(),\n",
    ")\n",
    "print(f\"naive MAE: {naive_mse}, model MAE: {model_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c68279-a7d6-4613-81c9-2498838efb55",
   "metadata": {},
   "source": [
    "## Referências\n",
    "\n",
    "1. [Traffic forecasting using graph neural networks ](https://www.kaggle.com/code/raihan150146/traffic-forecasting-using-graph-neural-networks)\n",
    "2. [Graph convolutional neural networks](https://mbernste.github.io/posts/gcn/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fec6f9-eba2-41c0-9ff1-4ddd3e8a2101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
